# Example study configuration
study:
  name: "vllm_optimization_example_3"
  database_url: "postgresql://tuner-user:${POSTGRES_PASSWORD}@localhost:5432/optuna"
  
optimization:
  # High-throughput optimization: Maximize token generation rate
  approach: "single_objective"
  objective:
    metric: "output_tokens_per_second"  # Throughput optimization
    direction: "maximize"
    percentile: "median"  # Use median for stable results
  sampler: "tpe"
  n_trials: 100
  
  # Alternative: Use preset for common configurations
  # preset: "high_throughput"
  
benchmark:
  benchmark_type: "guidellm"
  model: "Qwen/Qwen3-30B-A3B-FP8"
  max_seconds: 60
  dataset: null  # Use synthetic data
  prompt_tokens: 1000
  output_tokens: 1000
  
logging:
  # At least one of the following must be provided and must be valid
  database_url: "postgresql://tuner-user:${POSTGRES_PASSWORD}@localhost:5432/tuner-user" # Optional database url
  file_path: "/tmp/auto-tune-vllm-logs-local" # Optional local file path
  nfs_path: null  # Optional NFS mount
  log_level: "INFO"
  
parameters:
  max_num_batched_tokens:
    enabled: true
    # Uses schema defaults
    
  gpu_memory_utilization:
    enabled: true
    min: 0.9
    max: 0.95
    step: 0.01
    
  kv_cache_dtype:
    enabled: true
    options: ["auto", "fp8"]
    
  enable_cuda_graphs:
    enabled: false
