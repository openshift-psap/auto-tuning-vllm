# Example study configuration
study:
  name: "vllm_optimization_example_1"
  database_url: "postgresql://tuner-user:password@localhost:5432/optuna"
  
optimization:
  # Advanced multi-objective: Optimize throughput vs Time-To-First-Token
  approach: "multi_objective"
  objectives:
    - metric: "output_tokens_per_second"  # Maximize throughput
      direction: "maximize"
      percentile: "median"
    - metric: "time_to_first_token_ms"  # Minimize TTFT for responsiveness
      direction: "minimize"
      percentile: "p95"  # Focus on worst-case TTFT
  sampler: "nsga2"  # Best for multi-objective optimization
  n_trials: 100
  
benchmark:
  benchmark_type: "guidellm"
  model: "Qwen/Qwen3-30B-A3B-FP8"
  max_seconds: 300
  dataset: null  # Use synthetic data
  prompt_tokens: 1000
  output_tokens: 1000
  
logging:
  # At least one of the following must be provided and must be valid
  database_url: "postgresql://tuner-user:password@localhost:5432/tuner-user" # Optional database url
  file_path: "/tmp/auto-tune-vllm-logs" # Optional local file path
  nfs_path: null  # Optional NFS mount
  log_level: "INFO"
  
parameters:
  max_num_batched_tokens:
    enabled: true
    # Uses schema defaults
    
  gpu_memory_utilization:
    enabled: true
    min: 0.9
    max: 0.95
    step: 0.01
    
  kv_cache_dtype:
    enabled: true
    options: ["auto", "fp8"]
    
  enable_cuda_graphs:
    enabled: false